import json
import re
import os
from typing import List
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

from src.diff.diff import Change
import asyncio

# === üî• IMPORT TOOLS ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ===
from src.AI.Tools.tavily_search import get_web_tools

load_dotenv()

# ==================================================
# LLM setup
# ==================================================
llm = ChatOpenAI(
    base_url=os.getenv("LOCALMODEL_BASE_URL"),
    api_key=os.getenv("LOCALMODEL_API_KEY"),
    model=os.getenv("LOCALMODEL_MODEL_SUGGESTION"),
    temperature=0.2,
)

# ==================================================
# üîß REGISTER TOOLS (Tavily)
# ==================================================
tools = get_web_tools()  # ‡πÑ‡∏î‡πâ TavilySearchResults ‡πÄ‡∏õ‡πá‡∏ô list

# ‡∏ú‡∏π‡∏Å tools ‡∏Å‡∏±‡∏ö LLM
llm_with_tools = llm.bind_tools(tools)

# ==================================================
# Utility: Safe JSON Parser
# ==================================================
def _safe_parse_json(raw: str) -> dict:
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å LLM ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"""
    match = re.search(r"\{[\s\S]*\}", raw)
    if not match:
        print("‚ö†Ô∏è [DEBUG] ‡πÑ‡∏°‡πà‡∏û‡∏ö JSON ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° LLM")
        return {}
    try:
        return json.loads(match.group(0))
    except Exception as e:
        print(f"‚ö†Ô∏è [DEBUG] JSON parse error: {e}")
        cleaned = re.sub(r"[\x00-\x1f\x7f]", "", match.group(0))
        try:
            return json.loads(cleaned)
        except Exception as e2:
            print(f"‚ö†Ô∏è [DEBUG] Parse ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ã‡πâ‡∏≥: {e2}")
            return {}

# ==================================================
# Generate ai_suggestion (üî• ASYNC + TOOLS)
# ==================================================
async def generate_ai_suggestion(change: Change) -> None:
    prompt = ChatPromptTemplate.from_template("""
‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á:
{ai_comment}

üì° TOOLS ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô):
- ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢, ‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°
- ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ô‡∏¥‡∏¢‡∏≤‡∏°, ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏ô‡∏ß‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏≤‡πÄ‡∏≠‡∏á

‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:
- ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î‡∏Ñ‡∏≥,
  ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô, ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
  ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÑ‡∏õ‡∏ß‡πà‡∏≤
  "‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏î‡πÜ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
  ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ***‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏£‡πà‡∏ß‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ô‡∏µ‡πâ*** ‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏Å‡πá‡∏ï‡πà‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏Ñ‡πà‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡∏£‡∏£‡∏Ñ ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏∞‡∏Å‡∏î‡∏Ñ‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô

- ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á 2 ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà
  1) ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠ ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
  2) ‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠ ‡∏ú‡∏π‡πâ‡∏Ç‡∏≤‡∏¢
  ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÜ , ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á markdown ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÑ‡∏î‡πâ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°

‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON: {{ "ai_suggestion": "..." }}
""")

    chain = prompt | llm_with_tools | StrOutputParser()

    print(f"\nüõ†Ô∏è [DEBUG] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ai_suggestion ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Change: {change.change_type}")

    try:
        raw_output = await chain.ainvoke({
            "ai_comment": change.ai_comment,
            "legal": change.risk_scores.get("legal", 0) if hasattr(change, "risk_scores") else 0,
            "financial": change.risk_scores.get("financial", 0) if hasattr(change, "risk_scores") else 0,
            "operational": change.risk_scores.get("operational", 0) if hasattr(change, "risk_scores") else 0,
            "change_type": change.change_type,
            "old_text": change.old_text,
            "new_text": change.new_text,
        })

        raw_output = raw_output.strip()
        data = _safe_parse_json(raw_output)

        change.ai_suggestion = data.get(
            "ai_suggestion",
            "‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô"
        )

    except Exception as e:
        print(f"‚ùå [ERROR] ai_suggestion ‡∏•‡πà‡∏°: {e}")
        raise  # ‡πÉ‡∏´‡πâ wrapper ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ retry

# ==================================================
# Async wrapper for generate_ai_suggestion + RETRY
# ==================================================


async def generate_ai_suggestion_async(
    change: Change,
    semaphore: asyncio.Semaphore,
    max_retries: int = 2
):
    """
    Async wrapper ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö generate_ai_suggestion
    - ‡πÉ‡∏ä‡πâ semaphore ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏ô event loop ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
    """

    async with semaphore:
        last_error = None

        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    print(
                        f"üîÅ [RETRY {attempt}/{max_retries}] "
                        f"ai_suggestion | Change: {change.change_type}"
                    )

                await generate_ai_suggestion(change)
                return  # ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚Üí ‡∏≠‡∏≠‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô

            except Exception as e:
                last_error = e
                print(f"‚ùå [ASYNC ERROR] ai_suggestion attempt {attempt+1}: {e}")
                await asyncio.sleep(1.0)

        print(f"‚ùå [FATAL] ai_suggestion ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏´‡∏•‡∏±‡∏á retry {max_retries} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")

        # fallback (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÄ‡∏™‡∏°‡∏≠)
        change.ai_suggestion = (
            "‡∏Ñ‡∏ß‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô "
            f"(‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)"
        )


# ==================================================
# Run ai_suggestion in parallel
# ==================================================
async def run_generate_ai_suggestion_parallel(changes: List[Change]):
    """
    ‡∏¢‡∏¥‡∏á generate_ai_suggestion ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢ Change
    - ‡∏™‡∏£‡πâ‡∏≤‡∏á semaphore ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô event loop ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô error)
    """

    SEMAPHORE_LIMIT = int(os.getenv("LLM_PARALLEL_LIMIT", 8))
    semaphore = asyncio.Semaphore(SEMAPHORE_LIMIT)  # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ (‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)

    results = await asyncio.gather(
        *[
            generate_ai_suggestion_async(c, semaphore, max_retries=2)
            for c in changes
        ],
        return_exceptions=True
    )

    # Debug: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏Ñ‡∏™‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á error ‡∏à‡∏£‡∏¥‡∏á ‡πÜ
    for i, r in enumerate(results):
        if isinstance(r, Exception):
            print(f"‚ö†Ô∏è [PARALLEL ERROR] ai_suggestion | Change index {i}: {r}")

