from pathlib import Path
import logging
import time
from typing import Optional, List

from src.db.models import  Document
from src.db.session import SessionLocal
from src.db.ops import (
    create_document_version,
    create_comparison,
    bulk_insert_changes,
    save_document_pages,
)
from src.ingestion.document_load import DocumentLoader
from src.ingestion.paragraph import ParagraphSplitter
from src.embedding.embed import EmbeddingService
from src.match.paragraph_match import ParagraphMatcher
from src.match.match_resolver import MatchResolver
from src.diff.diff import DiffEngine, Change as DiffChange

from src.report.report_builder import ReportBuilder
import asyncio
from src.AI.ai_comment import (
    run_generate_ai_comment_parallel,
)
from src.AI.ai_suggestion import (
    run_generate_ai_suggestion_parallel,
)
from src.AI.ai_sum import build_summary_text

logger = logging.getLogger(__name__)


async def run_compare(
    doc_name: str,
    v1_file_bytes: Optional[bytes] = None,
    v2_file_bytes: Optional[bytes] = None,
    v1_filename: Optional[str] = None,
    v2_filename: Optional[str] = None,
    v1_label: str = "v1",
    v2_label: str = "v2",
) -> dict:
    """
    ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö PDF ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô

    ‚úÖ RULE (‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£):
    - document.id = comparison.id = changes.comparison_id
    - ‡∏•‡∏ö 9 ‚Üí ‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÑ‡∏î‡πâ 9 ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
    - ‡∏î‡∏π‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (MAX id) ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    """

    start_time = time.perf_counter()
    print("\nüïí ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤ run_compare ...")

    # ==================================================
    # Load PDFs
    # ==================================================
    print("üìÑ Loading Document...")
    loader = DocumentLoader()
    try:
        pages_old = loader.load_from_bytes(v1_file_bytes)
        pages_new = loader.load_from_bytes(v2_file_bytes)

        v1_filename = v1_filename or f"{doc_name}_{v1_label}.pdf"
        v2_filename = v2_filename or f"{doc_name}_{v2_label}.pdf"

        print(
            f"  Loaded {len(pages_old)} pages from V1, {len(pages_new)} pages from V2"
        )

    except Exception as e:
        logger.exception("‚ùå Failed to load PDFs")
        raise RuntimeError(f"Failed to load PDFs: {e}")

    # ==================================================
    # Split paragraphs
    # ==================================================
    print("‚úÇ Splitting paragraphs...")
    splitter = ParagraphSplitter()
    old_paragraphs = splitter.split(pages_old)
    new_paragraphs = splitter.split(pages_new)

    # ==================================================
    # Embedding
    # ==================================================
    print("üîó Embedding paragraphs...")
    embedder = EmbeddingService()
    embedder.embed_paragraphs(old_paragraphs)
    embedder.embed_paragraphs(new_paragraphs)

    # ==================================================
    # Matching
    # ==================================================
    print("üîç Matching paragraphs (Stage 1)...")
    matcher = ParagraphMatcher(threshold=0.75)
    stage1_matches = matcher.match(old_paragraphs, new_paragraphs)

    # ==================================================
    # Resolve
    # ==================================================
    print("üß† Resolving semantic changes (Stage 2)...")
    resolver = MatchResolver(chunk_threshold=0.85)
    resolved_matches = resolver.resolve(
        stage1_matches, old_paragraphs, new_paragraphs
    )

    # ==================================================
    # Diff
    # ==================================================
    print("üìù Building changes (Diff)...")
    diff_engine = DiffEngine()
    changes: List[DiffChange] = diff_engine.build_changes(resolved_matches)

    edit_intensity = diff_engine.compute_edit_intensity(changes)
    print("‚úèÔ∏è Edit Intensity:", edit_intensity)

    # ==================================================
    # AI summary + Risk
    # ==================================================
    print("ü§ñ LLM per-change analysis (parallel) ...")
    await run_generate_ai_comment_parallel(changes)
    await run_generate_ai_suggestion_parallel(changes)

    print("ü§ñ Building summary + impact analysis ...")
    summary_result = build_summary_text(changes)

    summary_text = summary_result["summary_text"]
    overall_risk_level = summary_result["overall_risk_level"]   # ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å AI ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    impact_scores = summary_result["impact_scores"]
    risk_comment = summary_result["risk_comment"]

    # ==================================================
    # üî• CORE FIX: ‡∏Ñ‡∏∏‡∏°‡πÄ‡∏•‡∏Ç document_id ‡πÄ‡∏≠‡∏á (‡∏î‡∏π‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î)
    # ==================================================
    db = SessionLocal()
    try:
        # ===== 1) ‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡πâ‡∏ß +1 (‡πÄ‡∏ï‡∏¥‡∏°‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡πâ‡∏≤‡∏¢)
        last_id = db.query(Document.id).order_by(Document.id.desc()).first()
        if last_id is None:
            new_id = 1
        else:
            new_id = last_id[0] + 1

        print(f"üÜî Using document_id = {new_id}")

        # ===== 2) ‡∏™‡∏£‡πâ‡∏≤‡∏á Document ‡∏à‡∏£‡∏¥‡∏á (‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏Ñ‡∏∏‡∏°‡πÄ‡∏≠‡∏á)
        real_doc = Document(id=new_id, name=doc_name)
        db.add(real_doc)
        db.flush()

        # ===== 3) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (‡πÉ‡∏ä‡πâ document_id = new_id)
        save_document_pages(
            db=db,
            document_id=new_id,
            pages=pages_old,
            pdf_name=v1_filename,
            version_pdf="old",
        )

        save_document_pages(
            db=db,
            document_id=new_id,
            pages=pages_new,
            pdf_name=v2_filename,
            version_pdf="new",
        )

        # ===== 4) ‡∏™‡∏£‡πâ‡∏≤‡∏á Version ‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ document ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        ver1 = create_document_version(db, real_doc, v1_label, v1_filename)
        ver2 = create_document_version(db, real_doc, v2_label, v2_filename)

        # ===== 5) ‡∏™‡∏£‡πâ‡∏≤‡∏á Comparison ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ id ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö document
        comp = create_comparison(
        db, real_doc, ver1, ver2, overall_risk_level, summary_text
        )

        comp.edit_intensity = edit_intensity

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏´‡∏°‡πà (‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Column ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏Å‡∏≥‡∏´‡∏ô‡∏î)
        comp.scope_impact_score = impact_scores["scope_impact_score"]
        comp.timeline_impact_score = impact_scores["timeline_impact_score"]
        comp.cost_impact_score = impact_scores["cost_impact_score"]
        comp.resource_impact_score = impact_scores["resource_impact_score"]
        comp.risk_impact_score = impact_scores["risk_impact_score"]
        comp.contract_impact_score = impact_scores["contract_impact_score"]
        comp.stakeholder_impact_score = impact_scores["stakeholder_impact_score"]
        comp.architecture_impact_score = impact_scores["architecture_impact_score"]

# (‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏£‡∏ß‡∏°)
        comp.risk_comment = risk_comment
        comp.overall_risk_level = overall_risk_level

        # ===== 6) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å changes (‡∏à‡∏∞‡πÑ‡∏î‡πâ changes.comparison_id = new_id)
        change_dicts: List[dict] = []
        for c in changes:
            change_dicts.append(
                {
                    "change_type": c.change_type,
                    "section_label": c.section_label,
                    "old_text": c.old_text,
                    "new_text": c.new_text,
                    "edit_severity": getattr(c, "edit_severity", None),
                    "ai_comment": getattr(c, "ai_comment", None),
                    "ai_suggestion": getattr(c, "ai_suggestion", None),
                }
            )

        bulk_insert_changes(db, comp, change_dicts)
        db.commit()
        run_id = comp.id   # = document_id

    except Exception:
        db.rollback()
        raise
    finally:
        db.close()

    # ==================================================
    # Build reports
    # ==================================================
    reporter = ReportBuilder()
    json_path = Path(
        reporter.save_json(doc_name, v1_label, v2_label, changes)
    )
    html_path = Path(
        reporter.save_html(
            doc_name,
            v1_label,
            v2_label,
            changes,
            summary_text,
            overall_risk_level,
            edit_intensity,
        )
    )

    # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
    end_time = time.perf_counter()
    elapsed_seconds = end_time - start_time
    minutes = int(elapsed_seconds // 60)
    seconds = elapsed_seconds % 60

    print(f"\n‚è±Ô∏è TOTAL RUNTIME: {round(elapsed_seconds, 2)} seconds "
          f"({minutes} minutes {round(seconds, 2)} seconds)")

    return {
        "doc_name": doc_name,
        "v1_label": v1_label,
        "v2_label": v2_label,
        "pages_v1": len(pages_old),
        "pages_v2": len(pages_new),
        "paragraphs_v1": len(old_paragraphs),
        "paragraphs_v2": len(new_paragraphs),
        "changes_count": len(changes),
        "edit_intensity": edit_intensity,
        "summary_text": summary_text,
        "overall_risk_level": overall_risk_level,
        "impact_scores": impact_scores,
        "risk_comment": risk_comment,
        "json_report_path": str(json_path),
        "html_report_path": str(html_path),
        "run_id": run_id,
        "html_report_url": f"/reports/{html_path.name}",
        "json_report_url": f"/reports/{json_path.name}",
        "runtime_minutes": minutes,
        "runtime_seconds": round(seconds, 2),
    }
