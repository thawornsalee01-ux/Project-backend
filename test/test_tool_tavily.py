import os
from dotenv import load_dotenv

from src.AI.Tools.tavily_search import get_web_tools
from langchain_openai import ChatOpenAI
from langchain.messages import SystemMessage, HumanMessage

# =========================
# Load environment variables
# =========================
load_dotenv()

# =========================
# 1) Search ‡∏î‡πâ‡∏ß‡∏¢ Tavily
# =========================
tools = get_web_tools()
search_tool = tools[0]

query = "‡∏ú‡∏π‡πâ‡∏ä‡∏ô‡∏∞‡πÅ‡∏ä‡∏°‡∏õ‡πå‡πÇ‡∏•‡∏Å F1 ‡∏õ‡∏µ2025‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£"
results = search_tool.run(query)

print("üîç Search Results:")
for r in results:
    print("-", r)

# =========================
# 2) ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô context
# =========================
def build_context(results, max_chars=4000):
    chunks = []
    total = 0

    for r in results:
        text = f"{r.get('title', '')} - {r.get('content', '')}"
        total += len(text)

        if total > max_chars:
            break

        chunks.append(text)

    return "\n".join(chunks)

context = build_context(results)

# =========================
# 3) ‡πÉ‡∏ä‡πâ Local LLM (OpenAI-compatible)
# =========================
llm = ChatOpenAI(
    base_url=os.getenv("LOCALMODEL_BASE_URL"),
    api_key=os.getenv("LOCALMODEL_API_KEY") or "local-key",  # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
    model=os.getenv("LOCALMODEL_MODEL_COMMENT"),
    temperature=0.2,
)

messages = [
    SystemMessage(
        content=(
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö "
            "‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö "
            "‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏î‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        )
    ),
    HumanMessage(
        content=f"""
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
{query}

‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö:
{context}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• ‡πÅ‡∏•‡∏∞‡∏õ‡∏µ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
"""
    ),
]

# =========================
# 4) ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM (LangChain ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏ä‡πâ invoke)
# =========================
response = llm.invoke(messages)

print("\nü§ñ AI Answer:")
print(response.content)
